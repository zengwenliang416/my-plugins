#!/usr/bin/env python3
"""
Excel æ•°æ®åˆ†æè„šæœ¬
ç”¨æ³•: python xlsx-analysis.py <xlsxæ–‡ä»¶è·¯å¾„> [å·¥ä½œè¡¨å]
"""

import sys
import os
import json
from datetime import datetime

try:
    import pandas as pd
except ImportError:
    print("è¯·å®‰è£…ä¾èµ–: pip install pandas openpyxl")
    sys.exit(1)


def analyze_dataframe(df: pd.DataFrame, sheet_name: str) -> dict:
    """åˆ†æ DataFrame"""
    analysis = {
        "sheet_name": sheet_name,
        "shape": {"rows": df.shape[0], "columns": df.shape[1]},
        "columns": list(df.columns),
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "missing": {col: int(count) for col, count in df.isnull().sum().items()},
        "missing_pct": {
            col: round(count / len(df) * 100, 2) if len(df) > 0 else 0
            for col, count in df.isnull().sum().items()
        },
        "duplicates": int(df.duplicated().sum()),
        "memory_kb": round(df.memory_usage(deep=True).sum() / 1024, 2),
    }

    # æ•°å€¼åˆ—ç»Ÿè®¡
    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    if numeric_cols:
        analysis["numeric_summary"] = {}
        for col in numeric_cols:
            analysis["numeric_summary"][col] = {
                "count": int(df[col].count()),
                "mean": (
                    round(float(df[col].mean()), 4)
                    if not pd.isna(df[col].mean())
                    else None
                ),
                "std": (
                    round(float(df[col].std()), 4)
                    if not pd.isna(df[col].std())
                    else None
                ),
                "min": float(df[col].min()) if not pd.isna(df[col].min()) else None,
                "max": float(df[col].max()) if not pd.isna(df[col].max()) else None,
                "median": (
                    float(df[col].median()) if not pd.isna(df[col].median()) else None
                ),
            }

    # åˆ†ç±»åˆ—ç»Ÿè®¡
    categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()
    if categorical_cols:
        analysis["categorical_summary"] = {}
        for col in categorical_cols:
            analysis["categorical_summary"][col] = {
                "unique": int(df[col].nunique()),
                "top_values": {
                    str(k): int(v) for k, v in df[col].value_counts().head(5).items()
                },
            }

    # æ—¥æœŸåˆ—ç»Ÿè®¡
    date_cols = df.select_dtypes(include=["datetime64"]).columns.tolist()
    if date_cols:
        analysis["date_summary"] = {}
        for col in date_cols:
            analysis["date_summary"][col] = {
                "min": str(df[col].min()) if not pd.isna(df[col].min()) else None,
                "max": str(df[col].max()) if not pd.isna(df[col].max()) else None,
            }

    return analysis


def analyze_xlsx(xlsx_path: str, sheet_name: str = None) -> dict:
    """åˆ†æ Excel æ–‡ä»¶"""
    xlsx = pd.ExcelFile(xlsx_path)
    sheet_names = xlsx.sheet_names

    if sheet_name:
        if sheet_name not in sheet_names:
            raise ValueError(f"å·¥ä½œè¡¨ '{sheet_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨: {sheet_names}")
        sheets_to_analyze = [sheet_name]
    else:
        sheets_to_analyze = sheet_names

    results = {
        "file": os.path.basename(xlsx_path),
        "analyzed_at": datetime.now().isoformat(),
        "total_sheets": len(sheet_names),
        "sheet_names": sheet_names,
        "sheets": [],
    }

    for name in sheets_to_analyze:
        df = pd.read_excel(xlsx, sheet_name=name)
        analysis = analyze_dataframe(df, name)
        results["sheets"].append(analysis)

    return results


def generate_report(analysis: dict) -> str:
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    report = f"""# Excel æ•°æ®åˆ†ææŠ¥å‘Š

**æ–‡ä»¶**: {analysis['file']}
**åˆ†ææ—¶é—´**: {analysis['analyzed_at']}
**å·¥ä½œè¡¨æ•°**: {analysis['total_sheets']}

## å·¥ä½œè¡¨åˆ—è¡¨

"""
    for name in analysis["sheet_names"]:
        report += f"- {name}\n"

    for sheet in analysis["sheets"]:
        report += f"""
---

## å·¥ä½œè¡¨: {sheet['sheet_name']}

### åŸºæœ¬ä¿¡æ¯

| æŒ‡æ ‡ | å€¼ |
|------|------|
| è¡Œæ•° | {sheet['shape']['rows']:,} |
| åˆ—æ•° | {sheet['shape']['columns']} |
| é‡å¤è¡Œ | {sheet['duplicates']} |
| å†…å­˜å ç”¨ | {sheet['memory_kb']:.2f} KB |

### åˆ—ä¿¡æ¯

| åˆ—å | ç±»å‹ | ç¼ºå¤±å€¼ | ç¼ºå¤±ç‡ |
|------|------|--------|--------|
"""
        for col in sheet["columns"]:
            dtype = sheet["dtypes"][col]
            missing = sheet["missing"].get(col, 0)
            missing_pct = sheet["missing_pct"].get(col, 0)
            report += f"| {col} | {dtype} | {missing} | {missing_pct}% |\n"

        if "numeric_summary" in sheet:
            report += "\n### æ•°å€¼åˆ—ç»Ÿè®¡\n\n"
            report += "| åˆ—å | è®¡æ•° | å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | ä¸­ä½æ•° |\n"
            report += "|------|------|------|--------|--------|--------|--------|\n"
            for col, stats in sheet["numeric_summary"].items():
                report += f"| {col} | {stats['count']} | {stats['mean']} | {stats['std']} | {stats['min']} | {stats['max']} | {stats['median']} |\n"

        if "categorical_summary" in sheet:
            report += "\n### åˆ†ç±»åˆ—ç»Ÿè®¡\n\n"
            for col, stats in sheet["categorical_summary"].items():
                report += f"#### {col}\n\n"
                report += f"- å”¯ä¸€å€¼æ•°é‡: {stats['unique']}\n"
                report += f"- Top 5 å€¼:\n"
                for val, count in stats["top_values"].items():
                    report += f"  - {val}: {count}\n"
                report += "\n"

    return report


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python xlsx-analysis.py <xlsxæ–‡ä»¶è·¯å¾„> [å·¥ä½œè¡¨å]")
        sys.exit(1)

    xlsx_path = sys.argv[1]
    sheet_name = sys.argv[2] if len(sys.argv) > 2 else None

    if not os.path.exists(xlsx_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {xlsx_path}")
        sys.exit(1)

    print(f"ğŸ“Š åˆ†æ Excel æ–‡ä»¶: {xlsx_path}")
    if sheet_name:
        print(f"   å·¥ä½œè¡¨: {sheet_name}")

    analysis = analyze_xlsx(xlsx_path, sheet_name)

    # ä¿å­˜ JSON ç»“æœ
    output_dir = os.path.dirname(xlsx_path) or "."
    json_path = os.path.join(output_dir, "xlsx-analysis.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜: {json_path}")

    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(analysis)
    report_path = os.path.join(output_dir, "xlsx-analysis-report.md")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(report)
    print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    # æ‰“å°æ‘˜è¦
    print(f"\nğŸ“Š åˆ†ææ‘˜è¦:")
    for sheet in analysis["sheets"]:
        print(f"\n   å·¥ä½œè¡¨: {sheet['sheet_name']}")
        print(f"   - è¡Œæ•°: {sheet['shape']['rows']:,}")
        print(f"   - åˆ—æ•°: {sheet['shape']['columns']}")
        print(f"   - é‡å¤è¡Œ: {sheet['duplicates']}")


if __name__ == "__main__":
    main()
