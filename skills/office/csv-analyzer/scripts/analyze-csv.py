#!/usr/bin/env python3
"""
CSV è‡ªåŠ¨åˆ†æè„šæœ¬
ç”¨æ³•: python analyze-csv.py <csvæ–‡ä»¶è·¯å¾„> [è¾“å‡ºç›®å½•]
"""

import sys
import os
import json
from datetime import datetime

try:
    import pandas as pd
    import matplotlib.pyplot as plt
    import seaborn as sns
except ImportError as e:
    print(f"è¯·å®‰è£…ä¾èµ–: pip install pandas matplotlib seaborn")
    print(f"ç¼ºå°‘æ¨¡å—: {e}")
    sys.exit(1)


def analyze_csv(path: str) -> dict:
    """åˆ†æ CSV æ–‡ä»¶"""
    df = pd.read_csv(path)

    analysis = {
        "file": os.path.basename(path),
        "analyzed_at": datetime.now().isoformat(),
        "shape": {"rows": df.shape[0], "columns": df.shape[1]},
        "columns": list(df.columns),
        "dtypes": {col: str(dtype) for col, dtype in df.dtypes.items()},
        "missing": {col: int(count) for col, count in df.isnull().sum().items()},
        "missing_pct": {
            col: round(count / len(df) * 100, 2)
            for col, count in df.isnull().sum().items()
        },
        "duplicates": int(df.duplicated().sum()),
        "memory_mb": round(df.memory_usage(deep=True).sum() / 1024 / 1024, 2),
    }

    # æ•°å€¼åˆ—ç»Ÿè®¡
    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()
    if numeric_cols:
        analysis["numeric_summary"] = {}
        for col in numeric_cols:
            analysis["numeric_summary"][col] = {
                "count": int(df[col].count()),
                "mean": (
                    round(float(df[col].mean()), 4)
                    if not pd.isna(df[col].mean())
                    else None
                ),
                "std": (
                    round(float(df[col].std()), 4)
                    if not pd.isna(df[col].std())
                    else None
                ),
                "min": float(df[col].min()) if not pd.isna(df[col].min()) else None,
                "max": float(df[col].max()) if not pd.isna(df[col].max()) else None,
                "median": (
                    float(df[col].median()) if not pd.isna(df[col].median()) else None
                ),
            }

    # åˆ†ç±»åˆ—ç»Ÿè®¡
    categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()
    if categorical_cols:
        analysis["categorical_summary"] = {}
        for col in categorical_cols:
            analysis["categorical_summary"][col] = {
                "unique": int(df[col].nunique()),
                "top_values": {
                    str(k): int(v) for k, v in df[col].value_counts().head(5).items()
                },
            }

    return analysis, df


def generate_visualizations(df: pd.DataFrame, output_dir: str):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    os.makedirs(output_dir, exist_ok=True)

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams["font.sans-serif"] = ["SimHei", "Arial Unicode MS", "DejaVu Sans"]
    plt.rcParams["axes.unicode_minus"] = False

    numeric_cols = df.select_dtypes(include=["number"]).columns.tolist()

    # æ•°å€¼åˆ—åˆ†å¸ƒ
    for col in numeric_cols[:5]:
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))

        df[col].hist(ax=axes[0], bins=30, edgecolor="black", alpha=0.7)
        axes[0].set_title(f"{col} Distribution")
        axes[0].set_xlabel(col)
        axes[0].set_ylabel("Frequency")

        df.boxplot(column=col, ax=axes[1])
        axes[1].set_title(f"{col} Box Plot")

        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, f"{col}_distribution.png"), dpi=100)
        plt.close()

    # ç›¸å…³æ€§çƒ­åŠ›å›¾
    if len(numeric_cols) > 1:
        plt.figure(figsize=(10, 8))
        correlation = df[numeric_cols].corr()
        sns.heatmap(
            correlation, annot=True, cmap="coolwarm", center=0, fmt=".2f", square=True
        )
        plt.title("Correlation Heatmap")
        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "correlation_heatmap.png"), dpi=100)
        plt.close()

    # åˆ†ç±»åˆ—æŸ±çŠ¶å›¾
    categorical_cols = df.select_dtypes(include=["object"]).columns.tolist()
    for col in categorical_cols[:3]:
        if df[col].nunique() <= 20:
            plt.figure(figsize=(10, 6))
            df[col].value_counts().head(10).plot(kind="bar", color="steelblue")
            plt.title(f"{col} Distribution")
            plt.xlabel(col)
            plt.ylabel("Count")
            plt.xticks(rotation=45, ha="right")
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f"{col}_bar.png"), dpi=100)
            plt.close()


def generate_report(analysis: dict, output_path: str):
    """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
    report = f"""# CSV æ•°æ®åˆ†ææŠ¥å‘Š

**æ–‡ä»¶**: {analysis['file']}
**åˆ†ææ—¶é—´**: {analysis['analyzed_at']}

## æ•°æ®æ¦‚è§ˆ

| æŒ‡æ ‡ | å€¼ |
|------|------|
| æ€»è¡Œæ•° | {analysis['shape']['rows']:,} |
| æ€»åˆ—æ•° | {analysis['shape']['columns']} |
| é‡å¤è¡Œ | {analysis['duplicates']} |
| å†…å­˜å ç”¨ | {analysis['memory_mb']} MB |

## åˆ—ä¿¡æ¯

| åˆ—å | ç±»å‹ | ç¼ºå¤±å€¼ | ç¼ºå¤±ç‡ |
|------|------|--------|--------|
"""
    for col in analysis["columns"]:
        dtype = analysis["dtypes"][col]
        missing = analysis["missing"].get(col, 0)
        missing_pct = analysis["missing_pct"].get(col, 0)
        report += f"| {col} | {dtype} | {missing} | {missing_pct}% |\n"

    if "numeric_summary" in analysis:
        report += "\n## æ•°å€¼åˆ—ç»Ÿè®¡\n\n"
        report += "| åˆ—å | è®¡æ•° | å‡å€¼ | æ ‡å‡†å·® | æœ€å°å€¼ | æœ€å¤§å€¼ | ä¸­ä½æ•° |\n"
        report += "|------|------|------|--------|--------|--------|--------|\n"
        for col, stats in analysis["numeric_summary"].items():
            report += f"| {col} | {stats['count']} | {stats['mean']} | {stats['std']} | {stats['min']} | {stats['max']} | {stats['median']} |\n"

    if "categorical_summary" in analysis:
        report += "\n## åˆ†ç±»åˆ—ç»Ÿè®¡\n\n"
        for col, stats in analysis["categorical_summary"].items():
            report += f"### {col}\n\n"
            report += f"- å”¯ä¸€å€¼æ•°é‡: {stats['unique']}\n"
            report += f"- Top 5 å€¼:\n"
            for val, count in stats["top_values"].items():
                report += f"  - {val}: {count}\n"
            report += "\n"

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)


def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python analyze-csv.py <csvæ–‡ä»¶è·¯å¾„> [è¾“å‡ºç›®å½•]")
        sys.exit(1)

    csv_path = sys.argv[1]
    output_dir = sys.argv[2] if len(sys.argv) > 2 else "./csv_analysis_output"

    if not os.path.exists(csv_path):
        print(f"æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        sys.exit(1)

    print(f"ğŸ“Š åˆ†æ CSV æ–‡ä»¶: {csv_path}")

    # åˆ†ææ•°æ®
    analysis, df = analyze_csv(csv_path)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # ä¿å­˜åˆ†æç»“æœ JSON
    json_path = os.path.join(output_dir, "analysis.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(analysis, f, ensure_ascii=False, indent=2)
    print(f"âœ… åˆ†æç»“æœå·²ä¿å­˜: {json_path}")

    # ç”Ÿæˆå¯è§†åŒ–
    print("ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    generate_visualizations(df, output_dir)

    # ç”ŸæˆæŠ¥å‘Š
    report_path = os.path.join(output_dir, "report.md")
    generate_report(analysis, report_path)
    print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    print(f"\nâœ… åˆ†æå®Œæˆï¼è¾“å‡ºç›®å½•: {output_dir}")


if __name__ == "__main__":
    main()
